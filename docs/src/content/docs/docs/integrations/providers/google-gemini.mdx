---
title: Google Gemini
description: SideSeat extracts model and token information from Google Gemini API calls via the Google Gen AI SDK.
---

import { Tabs, TabItem, Aside } from '@astrojs/starlight/components';

SideSeat automatically extracts model information, token usage, and costs from Google Gemini API calls made through the [Google Gen AI SDK](https://github.com/googleapis/python-genai).

<Aside type="note">
The Google Gen AI SDK is the unified SDK for both the Gemini Developer API and the Vertex AI Gemini API. It replaces the older `vertexai` and `google-generativeai` packages. Switch between APIs by toggling the `vertexai` flag on the client.
</Aside>

## Prerequisites

- SideSeat running locally (`sideseat`)
- SDK installed (`pip install sideseat[google-genai]`)
- Google API key or Google Cloud credentials configured

## Usage with Gemini Developer API

```python
from sideseat import SideSeat, Frameworks
from google import genai

SideSeat(framework=Frameworks.GoogleGenAI)

client = genai.Client(api_key="your-api-key")

response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="Hello!",
)
print(response.text)
```

## Usage with Vertex AI

```python
from sideseat import SideSeat, Frameworks
from google import genai

SideSeat(framework=Frameworks.GoogleGenAI)

client = genai.Client(
    vertexai=True,
    project="your-project",
    location="us-central1",
)

response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="Hello!",
)
print(response.text)
```

## Extracted Attributes

| Attribute | Source |
|-----------|--------|
| `gen_ai.system` | `google_genai` |
| `gen_ai.request.model` | Model name |
| `gen_ai.response.model` | Response model field |
| `gen_ai.usage.input_tokens` | Usage metadata |
| `gen_ai.usage.output_tokens` | Usage metadata |

## Streaming

Streaming responses are captured:

```python
client = genai.Client(api_key="your-api-key")

for chunk in client.models.generate_content_stream(
    model="gemini-2.5-flash",
    contents="Tell me a story",
):
    print(chunk.text, end="")
```

## Chat Sessions

Multi-turn conversations are traced:

```python
client = genai.Client(api_key="your-api-key")
chat = client.chats.create(model="gemini-2.5-flash")

response1 = chat.send_message("Hello!")
response2 = chat.send_message("Tell me more")
```

## Function Calling

Tool use is captured:

```python
from google.genai.types import FunctionDeclaration, Tool

get_weather = FunctionDeclaration(
    name="get_weather",
    description="Get weather for a location",
    parameters={
        "type": "object",
        "properties": {
            "location": {"type": "string"}
        }
    }
)

tool = Tool(function_declarations=[get_weather])

response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="What's the weather in Paris?",
    config={"tools": [tool]},
)
```

## Authentication

```bash
# Gemini Developer API — use an API key
export GOOGLE_API_KEY=your-api-key

# Vertex AI — use Google Cloud credentials
gcloud auth application-default login
# Or service account
export GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
```

## Next Steps

- [First Run](/docs/quickstart/) -- get started with SideSeat
- [Python SDK](/docs/sdks/python/) -- SDK reference
